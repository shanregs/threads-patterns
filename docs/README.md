# Java Concurrency Patterns - Theory & Documentation

This folder contains comprehensive theory documents, thread flow analyses, and use case explanations for all concurrency patterns implemented in this project.

## üìö Documentation Structure

### Thread Flow Analysis Documents

#### 1. [CompletableFuture Thread Flow Analysis](COMPLETABLE_FUTURE_THREAD_FLOW_ANALYSIS.md)
**Topic**: Understanding CompletableFuture thread execution with ForkJoinPool.commonPool()

**What You'll Learn**:
- How ForkJoinPool.commonPool() works (default thread pool)
- Sequential vs parallel operations with CompletableFuture
- Thread execution timelines with detailed diagrams
- When operations run in parallel vs sequentially
- How `thenApply()`, `thenCompose()`, `thenCombine()` use threads
- Waiting and combining mechanisms
- Performance optimization strategies

**Key Sections**:
- Example 1: Basic Chaining (Sequential) - ~2400ms total
- Example 2: Combining (Parallel) - ~1000ms total (1.8x speedup!)
- Example 3: Error Handling - thread execution on errors
- Thread pool behavior and work-stealing algorithm

**Best For**: Understanding default CompletableFuture behavior before moving to custom pools

---

#### 2. [Why Thread Reuse](WHY_THREAD_REUSE.md)
**Topic**: Deep dive into ForkJoinPool thread reuse behavior

**What You'll Learn**:
- Why you see same thread IDs (worker-1, worker-2) repeatedly
- Why worker-3, worker-4, etc. often stay IDLE
- ForkJoinPool work-stealing algorithm explained
- Thread state timelines (IDLE vs BUSY)
- When additional threads are actually used
- Cache locality and performance benefits

**Key Insight**:
```
Sequential operations (one at a time):
  - Only 1 task running at a time
  - Uses 1-2 threads (reused from pool)
  - worker-3, worker-4, ... stay IDLE (not needed)

Parallel operations (simultaneous):
  - Multiple tasks running at once
  - Uses many threads (worker-1, 2, 3, 4, 5...)
  - Pool activates threads based on demand
```

**Includes**: Proof examples showing sequential vs parallel thread usage

---

#### 3. [Custom Pool Patterns Theory](CUSTOM_POOL_PATTERNS_THEORY.md)
**Topic**: Using custom ExecutorService pools instead of common pool

**What You'll Learn**:
- Why use custom pools vs ForkJoinPool.commonPool()
- Creating and configuring custom thread pools
- Sequential operations with custom pools
- Parallel operations with custom pools
- Using multiple pools together (I/O pool + CPU pool + Common pool)
- Pool sizing strategies (I/O-bound vs CPU-bound)
- Thread execution patterns and best practices
- Real-world examples and use cases

**Pool Strategy Table**:
| Task Type | Pool | Size | Why |
|-----------|------|------|-----|
| Database, Network, File I/O | I/O Pool | Large (2 √ó processors) | Threads block waiting |
| Computation, Processing | CPU Pool | processors | Threads always busy |
| Quick transforms | Common Pool | processors - 1 | General purpose |

**Key Patterns**:
1. **Fan-Out/Fan-In**: Parallel data loading ‚Üí Combine results
2. **Pipeline**: Sequential processing chain
3. **Hybrid**: Parallel fetching + Sequential processing

**Best For**: Production applications with specific performance requirements

---

#### 4. [Multi-Hop Tour Example](MULTI_HOP_TOUR_EXAMPLE.md)
**Topic**: CyclicBarrier pattern with real-world multi-phase synchronization

**What You'll Learn**:
- Using CyclicBarrier for multi-phase coordination
- Barrier actions (group activities after synchronization)
- Reusable barriers (cyclic nature)
- Thread synchronization across multiple phases
- Real-world use case: Tour guide coordinating tourists

**Scenario**: 5 tourists visit 4 city attractions
```
Tourist 1: Travel ‚Üí Explore ‚Üí [Wait at Barrier] ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
Tourist 2: Travel ‚Üí Explore ‚Üí [Wait at Barrier] ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
Tourist 3: Travel ‚Üí Explore ‚Üí [Wait at Barrier] ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚Üí [All Arrived!]
Tourist 4: Travel ‚Üí Explore ‚Üí [Wait at Barrier] ‚îÄ‚îÄ‚îÄ‚îÄ‚î§   [Group Activity]
Tourist 5: Travel ‚Üí Explore ‚Üí [Wait at Barrier] ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   [Proceed to Next]
```

**Applications**: Batch processing, simulations, distributed computing, game development

---

## üéØ Use Cases & Patterns

### By Concurrency Primitive

| Pattern | Use Case | Document | Example Code |
|---------|----------|----------|--------------|
| **CompletableFuture (Common Pool)** | Async API calls, non-blocking operations | [Thread Flow Analysis](COMPLETABLE_FUTURE_THREAD_FLOW_ANALYSIS.md) | `completablefuture/` |
| **CompletableFuture (Custom Pool)** | Production apps, resource control, I/O vs CPU separation | [Custom Pool Theory](CUSTOM_POOL_PATTERNS_THEORY.md) | `custompoolpatterns/` |
| **CountDownLatch** | Wait for multiple tasks to complete, batch coordination | N/A | `countdownlatch/` |
| **CyclicBarrier** | Multi-phase synchronization, reusable barriers | [Multi-Hop Tour](MULTI_HOP_TOUR_EXAMPLE.md) | `cyclicbarrier/` |
| **Phaser** | Dynamic participant count, flexible phase control | N/A | `phaser/` |
| **Semaphore** | Resource pooling, rate limiting, access control | N/A | `semaphore/` |
| **Exchanger** | Data exchange between threads, pipeline stages | N/A | `exchanger/` |
| **ThreadLocal** | Thread-specific context, request-scoped data | N/A | `threadlocal/` |
| **ReentrantLock** | Advanced locking, fairness, tryLock, conditions | N/A | `reentrantlock/` |
| **BlockingQueue** | Producer-consumer, work queues, task distribution | N/A | `blockingqueue/` |
| **ForkJoinPool** | Divide-and-conquer, recursive tasks, work-stealing | N/A | `forkjoinpool/` |
| **VirtualThreads** | Massive concurrency, lightweight threads (Java 21+) | N/A | `virtualthreads/` |
| **ExecutorService** | Thread pool types, queue strategies, task management | N/A | `executorservice/` |

---

## üîç Thread Flow Patterns

### Pattern 1: Sequential Operations
**Characteristics**: Tasks depend on previous results

**Thread Flow**:
```
Thread-1: Task A (500ms)
          ‚Üì
Thread-2: Task B (700ms)  ‚Üê Must wait for A
          ‚Üì
Thread-1: Task C (300ms)  ‚Üê Must wait for B

Total: 1500ms (sum of all)
```

**Code Pattern**:
```java
CompletableFuture.supplyAsync(() -> taskA())
    .thenCompose(a -> CompletableFuture.supplyAsync(() -> taskB(a)))
    .thenCompose(b -> CompletableFuture.supplyAsync(() -> taskC(b)));
```

**Documents**:
- [CompletableFuture Thread Flow - Example 1](COMPLETABLE_FUTURE_THREAD_FLOW_ANALYSIS.md#example-1-basic-chaining-sequential-operations)
- [Custom Pool Sequential](CUSTOM_POOL_PATTERNS_THEORY.md#sequential-operations)

---

### Pattern 2: Parallel Operations
**Characteristics**: Independent tasks run simultaneously

**Thread Flow**:
```
Thread-1: Task A (800ms)  ‚îê
Thread-2: Task B (1000ms) ‚îº‚îÄ All run in parallel
Thread-3: Task C (600ms)  ‚îò

Total: 1000ms (max of all)
Speedup: 2.4x vs sequential
```

**Code Pattern**:
```java
CompletableFuture<A> futureA = CompletableFuture.supplyAsync(() -> taskA());
CompletableFuture<B> futureB = CompletableFuture.supplyAsync(() -> taskB());
CompletableFuture<C> futureC = CompletableFuture.supplyAsync(() -> taskC());

CompletableFuture.allOf(futureA, futureB, futureC).join();
```

**Documents**:
- [CompletableFuture Thread Flow - Example 2](COMPLETABLE_FUTURE_THREAD_FLOW_ANALYSIS.md#example-2-combining-parallel-operations)
- [Custom Pool Parallel](CUSTOM_POOL_PATTERNS_THEORY.md#parallel-operations)

---

### Pattern 3: Hybrid (Parallel + Sequential)
**Characteristics**: Parallel data fetching followed by sequential processing

**Thread Flow**:
```
Parallel Phase:
  Thread-1: Fetch User (500ms)    ‚îê
  Thread-2: Fetch Orders (700ms)  ‚îº‚îÄ Parallel
  Thread-3: Fetch Prefs (400ms)   ‚îò
                                  ‚Üì
Sequential Phase:
  Thread-4: Combine Data (300ms)
            ‚Üì
  Thread-4: Process (500ms)
            ‚Üì
  Thread-5: Save (200ms)

Total: ~1700ms (max(500,700,400) + 300 + 500 + 200)
```

**Code Pattern**:
```java
// Parallel phase
CompletableFuture<User> user = supplyAsync(() -> fetchUser(), ioPool);
CompletableFuture<Orders> orders = supplyAsync(() -> fetchOrders(), ioPool);
CompletableFuture<Prefs> prefs = supplyAsync(() -> fetchPrefs(), ioPool);

// Sequential phase
CompletableFuture<Result> result = allOf(user, orders, prefs)
    .thenComposeAsync(v -> combineData(user.join(), orders.join(), prefs.join()), cpuPool)
    .thenComposeAsync(combined -> processData(combined), cpuPool)
    .thenComposeAsync(processed -> saveData(processed), ioPool);
```

**Documents**: [Custom Pool Theory - Hybrid Pattern](CUSTOM_POOL_PATTERNS_THEORY.md#pattern-3-hybrid-parallel--sequential)

---

## üèÜ Best Practices Summary

### 1. Common Pool vs Custom Pool

**Use Common Pool (ForkJoinPool.commonPool()) When**:
- ‚úÖ Quick, lightweight transformations
- ‚úÖ Non-blocking operations
- ‚úÖ General-purpose async tasks
- ‚úÖ Prototyping and simple applications

**Use Custom Pool When**:
- ‚úÖ I/O-bound operations (database, network, file)
- ‚úÖ CPU-intensive computations
- ‚úÖ Need resource isolation or limits
- ‚úÖ Production applications
- ‚úÖ Different pools for different workload types

### 2. Pool Sizing Rules

**I/O-Bound Tasks**:
```java
int poolSize = 2 * Runtime.getRuntime().availableProcessors();
// Threads block on I/O, so more threads = better throughput
```

**CPU-Bound Tasks**:
```java
int poolSize = Runtime.getRuntime().availableProcessors();
// Threads always busy, more threads = context switching overhead
```

**Mixed Workload**:
```java
int poolSize = Runtime.getRuntime().availableProcessors() + 1;
// Start here and tune based on monitoring
```

### 3. Common Mistakes to Avoid

**‚ùå Mistake 1: Forgetting executor in chain**
```java
CompletableFuture.supplyAsync(() -> task1(), customPool)
    .thenCompose(r -> CompletableFuture.supplyAsync(() -> task2(r)))
    // ‚ùå task2 uses COMMON POOL! (no executor specified)
```

**‚úÖ Correct**:
```java
CompletableFuture.supplyAsync(() -> task1(), customPool)
    .thenCompose(r -> CompletableFuture.supplyAsync(() -> task2(r), customPool))
    // ‚úÖ Explicitly specify custom pool
```

**‚ùå Mistake 2: Chaining independent operations**
```java
// BAD: Sequential (1800ms)
supplyAsync(() -> fetchA())              // 800ms
    .thenCompose(a -> supplyAsync(() -> fetchB()));  // 1000ms
```

**‚úÖ Correct**:
```java
// GOOD: Parallel (1000ms)
CompletableFuture<A> fa = supplyAsync(() -> fetchA());
CompletableFuture<B> fb = supplyAsync(() -> fetchB());
fa.thenCombine(fb, combiner);
```

**‚ùå Mistake 3: Not shutting down custom pools**
```java
ExecutorService pool = Executors.newFixedThreadPool(10);
// Use pool...
// ‚ùå Never shutdown = memory leak!
```

**‚úÖ Correct**:
```java
ExecutorService pool = Executors.newFixedThreadPool(10);
try {
    // Use pool...
} finally {
    pool.shutdown();
    pool.awaitTermination(5, TimeUnit.SECONDS);
}
```

---

## üìä Performance Comparisons

### Sequential vs Parallel

**Example from CompletableFuture demos**:
```
Sequential: 800ms + 1000ms + 600ms = 2400ms
Parallel:   max(800ms, 1000ms, 600ms) = 1000ms
Speedup:    2.4x faster
```

### Common Pool vs Custom Pool

**Resource Control**:
- Common Pool: Shared by entire JVM, risk of saturation
- Custom Pool: Dedicated resources, isolation, control

**Sizing**:
- Common Pool: Fixed at processors - 1
- Custom Pool: Optimized for workload (I/O vs CPU)

**Lifecycle**:
- Common Pool: JVM-managed, cannot shutdown
- Custom Pool: Application-managed, explicit shutdown

---

## üó∫Ô∏è Navigation Guide

### For Beginners
1. Start with [CompletableFuture Thread Flow Analysis](COMPLETABLE_FUTURE_THREAD_FLOW_ANALYSIS.md)
2. Understand [Why Thread Reuse](WHY_THREAD_REUSE.md)
3. Run demos in `completablefuture/` package
4. Practice identifying sequential vs parallel patterns

### For Intermediate Users
1. Read [Custom Pool Patterns Theory](CUSTOM_POOL_PATTERNS_THEORY.md)
2. Understand I/O vs CPU pool separation
3. Run demos in `custompoolpatterns/` package
4. Apply patterns to your own applications

### For Advanced Users
1. Study [Multi-Hop Tour Example](MULTI_HOP_TOUR_EXAMPLE.md) for complex synchronization
2. Explore all concurrency primitives in respective packages
3. Combine multiple patterns for complex workflows
4. Optimize based on profiling and monitoring

---

## üìÅ Related Code Packages

- **`completablefuture/`** - CompletableFuture with common pool examples
- **`custompoolpatterns/`** - Custom ExecutorService pool patterns
- **`cyclicbarrier/`** - CyclicBarrier synchronization examples
- **`countdownlatch/`** - CountDownLatch coordination examples
- **`phaser/`** - Phaser multi-phase synchronization
- **`semaphore/`** - Semaphore resource control
- **`exchanger/`** - Exchanger data exchange
- **`threadlocal/`** - ThreadLocal context management
- **`reentrantlock/`** - ReentrantLock advanced locking
- **`blockingqueue/`** - BlockingQueue producer-consumer
- **`forkjoinpool/`** - ForkJoinPool divide-and-conquer
- **`virtualthreads/`** - Virtual threads (Java 21+)
- **`executorservice/`** - ExecutorService types and strategies

---

## üéØ Quick Reference

### Choosing the Right Pattern

**Need to wait for multiple tasks?** ‚Üí CountDownLatch or CompletableFuture.allOf()

**Need reusable synchronization points?** ‚Üí CyclicBarrier

**Need dynamic participant count?** ‚Üí Phaser

**Need to limit concurrent access?** ‚Üí Semaphore

**Need thread-specific data?** ‚Üí ThreadLocal

**Need async composition?** ‚Üí CompletableFuture

**Need producer-consumer?** ‚Üí BlockingQueue

**Need divide-and-conquer?** ‚Üí ForkJoinPool

**Need massive concurrency?** ‚Üí Virtual Threads

---

## üìû Support

- **Detailed Examples**: See code in respective package folders
- **Running Demos**: Each package has a `Main.java` class
- **Thread Flow Questions**: Refer to analysis documents in this folder
- **Pattern Selection**: Use the use cases table above

---

**Happy Concurrent Programming! üöÄ**
